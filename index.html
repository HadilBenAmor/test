<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML Service Misuses</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    
    <header>
        <nav>
            <ul>
                <li><a href="#" data-modal="modalAbout">About</a></li>
               
            </ul>
        </nav>
        
   <!-- Modal Templates -->

<div id="modalAbout" class="modal about-modal">
    <div class="modal-content about-modal-content">
        <span class="close-btn" data-modal="modalAbout">&times;</span>
        <h2>About Details</h2>
        <p>This website was developed as part of research focused on the misuses associated with machine learning (ML) 
            cloud services. The goal of the research was to analyze 
            common pitfalls and identify ways to optimize the use of these services, ensuring they are implemented effectively and ethically.</p>
    </div>
</div>


        <h1>ML Cloud Services Misuses</h1>
    </header>
    <main>
        <section class="hero">
            <h2>Catalog Proposal</h2>
        </section>
      
        <section class="services">

            <div class="service-grid">
                <!-- Repeat the following block for each service -->
                <div class="service-item">
                    <h4>Inefficient data transmission</h4>
                    <div class="label">Data Collection and Preprocessing</div>
                    <p>Refers to sub-optimal data transmission between
                        components within an ML service-based system, such as between storage
                        services, compute nodes, and other cloud resources. This results in increased
                        latency, higher costs, and decreased performance.</p>
                    <button class="open-modal" data-modal="modal1">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Not using batch API for data loading</h4>
                    <div class="label">Data Collection and Preprocessing</div>
                    <p>Cloud providers offer batch-processing
                        APIs to optimize data loading performance by handling data in batches.
                        However, developers sometimes fail to use these batch APIs, opting instead
                        to load data items individually or implement their batch-processing solutions.
                        This misuse can lead to increased data transfer times, higher memory
                        usage, and reduced overall performance. </p>
                    <button class="open-modal" data-modal="modal2">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Non specification of early stopping criteria</h4>
                    <div class="label">Training</div>
                    <p>ML cloud services often provide options for setting early stopping criteria to prevent overfitting and reduce unnecessary computational costs.</p>
                    <button class="open-modal" data-modal="modal3">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Avoiding parallel training experiments</h4>
                    <div class="label">Training</div>
                    <p>Cloud providers offer the capability
                        to run parallel training experiments to speed up the model training process
                        and improve the efficiency of the system. Disabling parallel experiments can
                        slow down the model development process and limit the exploration of different
                        approaches within using the same resources to find the best-performing model.
                       </p>
                    <button class="open-modal" data-modal="modal4">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Not using automatic hyperparameter tuning</h4>
                    <div class="label">Training</div>
                    <p>ML cloud providers offer
                        the capability to define the search space and automatically optimize ML models
                        hyperparameters.</p>
                    <button class="open-modal" data-modal="modal5">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Not using training checkpoints</h4>
                    <div class="label">Training</div>
                    <p>Cloud providers offer the functionality to
                        resume training from the most recent checkpoint to save the current
                        state of the experiment, rather than starting from scratch. This can save significant time and
                        computational resources, especially when training large and complex models.However, developers 
                        may neglect to save training checkpoints in cloud storage.
                       </p>
                    <button class="open-modal" data-modal="modal6">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Bad choice of training compute targets</h4>
                    <div class="label">Training</div>
                    <p>Refers to selecting the non-optimal
                        hardware and compute resources for training ML models. Cloud providers offer
                        various types of training that compute targets, yet not all resources can be used
                        for automated machine learning, machine learning pipelines, or designer.
                       </p>
                    <button class="open-modal" data-modal="modal7">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Excluding algorithms in automated ML</h4>
                    <div class="label">Training</div>
                    <p>Cloud providers offer automated
                        machine learning services that, for a given prediction task, perform experiments
                        with various ML algorithms to generate an optimized model ready for deployment. 
                        However, developers may mistakenly exclude a promising candidate.
                        algorithms when configuring these services, thereby limiting the effectiveness and
                        performance of the resulting model.</p>
                    <button class="open-modal" data-modal="modal8">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Misinterpreting output</h4>
                    <div class="label">Testing</div>
                    <p>ML services offer pre-built models that operate
                        on high-dimensional continuous representations yet often ultimately produce a
                        small discrete set of outputs. Consequently, ML services’ output can contain
                        complicated, easily misinterpretable semantics, leading to bugs.</p>
                    <button class="open-modal" data-modal="modal9">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Ignoring fairness evaluation</h4>
                    <div class="label">Testing</div>
                    <p>ML cloud providers offer the possibility of fairness.
                        evaluation, which is crucial to ensure unbiased and equitable models. However,
                        developers may rely solely on performance metrics such as accuracy or precision
                        to evaluate the effectiveness of a model.</p>
                    <button class="open-modal" data-modal="modal10">Learn More</button>
                </div>
             
                <div class="service-item">
                    <h4>Ignoring testing schema mismatch</h4>
                    <div class="label">Testing</div>
                    <p>Cloud providers offer ML services to
                        detect unmatched data schemas, which include feature or data distribution mismatches
                        between training, testing, and production data, often by raising
                        alerts. However, developers might ignore setting up these alerts or may disable
                        them.</p>
                    <button class="open-modal" data-modal="modal11">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Using suboptimal evaluation metrics</h4>
                    <div class="label">Testing</div>
                    <p>Some ML services optimize and evaluate
                        models based on a set of specified evaluation metrics. Those metrics determine
                        how the model’s performance is measured during training and how it
                        should be evaluated during testing. However, developers sometimes choose suboptimal
                        evaluation metrics, which can lead to less effective models that do not
                        align well with business needs or dataset characteristics.</p>
                    <button class="open-modal" data-modal="modal12">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Overwriting existing ML APIs without versioning</h4>
                    <div class="label">Deployment</div>
                    <p>Cloud providers
                        ensures ML API versioning in through several practices such as Azure API management
                        and AWS Management Console. Without version control, it becomes challenging to track changes, 
                        revert to previous versions, or understand
                        the evolution of the deployed model. However, developers may ignore using those
                        practices and unintentionally overwrite existing ML APIs without proper versioning.
                        which can lead to potential issues in the production environment.</p>
                    <button class="open-modal" data-modal="modal13">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Choosing the wrong deployment endpoint</h4>
                    <div class="label">Deployment</div>
                    <p>Cloud providers offer online
                        endpoints and batch endpoints for deployment. Online endpoints are mainly
                        to operationalize models for real-time inference in synchronous low-latency requests.
                        Meanwhile, batch endpoints are mainly to operationalize models or pipelines
                        for long-running asynchronous inference. However, developers may choose
                        the inappropriate deployment endpoint.</p>
                    <button class="open-modal" data-modal="modal14">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Disabling automatic rollbacks</h4>
                    <div class="label">Deployment</div>
                    <p>ML cloud service providers offer features
                        that automatically roll back to a previous stable version of a model if the newly
                        deployed version causes errors or performance issues. However, developers might
                        disable this feature, allowing poorly performing models to remain in production
                        and negatively impact the system’s performance</p>
                    <button class="open-modal" data-modal="modal15">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Disabling automatic scaling for online prediction service</h4>
                    <div class="label">Deployment</div>
                    <p>Automatic scaling for online prediction service helps manage varying rates of prediction requests while minimizing cloud usage costs. 
                        Disabling this 
                        feature stops dynamically adjusting resources based on demand to ensure sufficient capacity for online prediction services. </p>
                    <button class="open-modal" data-modal="modal16">Learn More</button>
                </div>
             
                <div class="service-item">
                    <h4>Improper handling of ML API limits</h4>
                    <div class="label">Serving</div>
                    <p>Refers to the non-respect of API
                        rate limiting. Those limits are a set of measures put in place to help ensure the
                        stability and performance of the ML API system. However, developers
                        may not take care of limits for a cloud-based ML API, leading to a sudden stop
                        in predictions when the quota is exceeded.</p>
                    <button class="open-modal" data-modal="modal17">Learn More</button>
                </div>
                <div class="service-item">
                    <h4>Misusing Synchronous/<wbr>Asynchronous APIs with deployment type</h4>
                    <div class="label">Serving</div>
                    <p>Refers to using the inappropriate APIs for the deployment endpoint. It is not recommended
                        to use asynchronous API requests with online predictions, meaning in
                        situations that require timely inference and using synchronous APIs with batch
                        endpoint deployment, meaning when an immediate response is not required and
                        processing accumulated data by using a single request is sufficient.</p>
                    <button class="open-modal" data-modal="modal18">Learn More</button>
                </div>
                
                <div class="service-item">
                    <h4>Calling the wrong ML service API</h4>
                    <div class="label">Serving</div>
                    <p>Cloud providers often offer multiple
                        ML APIs for the same task. Without a thorough understanding of these APIs,
                        developers might call the wrong one, leading to the significantly degraded prediction
                        accuracy, incorrect prediction results, or even software failures.</p>
                    <button class="open-modal" data-modal="modal20">Learn More</button>
                </div>
                

                <div class="service-item">
                    <h4>Ignore monitoring data drift</h4>
                    <div class="label">Monitoring</div>
                    <p>Refers to ignoring the need to continually assess modifications to the statistical characteristics or distribution of data
                        used to ensure the expected performance. Cloud providers encourage using skew
                        and drift detection to detect when the statistical properties of the incoming
                        data change over time in a way that affects the ML service-based system.
                        </p>
                    <button class="open-modal" data-modal="modal21">Learn More</button>
                </div>

                
            </div>
        </section>
    </main>
    <footer>
        <p>&copy; 2024</p>
    </footer>

 <!-- Modal Templates -->
 <div id="modal1" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal1">&times;</span>
        <h2>Inefficient data transmission</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Data Collection and Preprocessing</p>
        
        <h3>Example:</h3><p>Repeatedly
            Transferring training data from cloud storage to compute 
            nodes for each job instead of caching it locally can lead to significant delays in training time and increased
            network traffic, and higher data transfer costs.
</p>

        <h3>References:</h3>
        <ul>
            <li> <p>Cao, J., Chen, B., Sun, C., Hu, L., Wu, S., Peng, X.: Understanding performance problems in deep learning systems.
                 In: Proceedings of the 30th ACM Joint European 
                Software Engineering Conference and Symposium on the Foundations of Software Engineering. pp. 357–369 (2022)</p></li>
    
        </ul>
    </div>
</div>

<div id="modal2" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal2">&times;</span>
        <h2>Not using batch API for data loading</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Data Collection and Preprocessing</p>
        
        <h3>Example:</h3> <p>Not using a batch API can
            cause out-of-memory errors, excessive network traffic, and significant delays in
            data loading, ultimately slowing down model training and increasing operational costs.
</p>

        <h3>References:</h3>
        <ul>
            <li> <p>Cao, J., Chen, B., Sun, C., Hu, L., Wu, S., Peng, X.: Understanding performance problems in deep learning systems.
                In: Proceedings of the 30th ACM Joint European 
               Software Engineering Conference and Symposium on the Foundations of Software Engineering. pp. 357–369 (2022)</p></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/search/search-howto-large-index#batch-multiple-documents-per-request" target="_blank">Batch API </a></li>

        </ul>
    </div>
</div>

<div id="modal3" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal3">&times;</span>
        <h2>Non specification of early stopping criteria</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Training</p>
        
        <h3>Example:</h3>
        <p>Developers might neglect
            to specify these criteria, allowing training to continue for more epochs.
            than needed. This misuse can lead to wasted computational resources and increased
            training times, higher costs, and potential overfitting.
</p>

        <h3>References:</h3>
        <ul>
            <li> <p>Xue Ying. An overview of overfitting and its solutions. In Journal of
                physics: Conference series, volume 1168, page 022022. IOP Publishing,
                2019.</p></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters?view=azureml-api-2" target="_blank">Early stopping criteria</a></li>
 
        </ul>
    </div>
</div>
<div id="modal4" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal4">&times;</span>
        <h2>Avoiding parallel training experiments</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Training</p>
        
        <h3>Example:</h3>
        <p>
            Running only one training experiment at a time instead of concurrently testing multiple configurations may reduce 
            efficiency because we can not quickly compare different models or hyperparameters, which is essential 
            for optimizing model performance.

        </p>
        <h3>References:</h3>
        <ul>
            <li> <p>Serban, A., Van der Blom, K., Hoos, H., Visser, J.: Adoption and effects of software engineering best practices in machine learning. In: Proceedings of the 14th
                ACM/IEEE International Symposium on Empirical Software Engineering and
                Measurement (ESEM). pp. 1–12 (2020)</p></li>
                <li><a href="https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/train-and-score-hundreds-of-thousands-of-models-in-parallel/ba-p/1547960" target="_blank">Train and Score Hundreds of Thousands of Models in Parallel</a></li>
            <li><a href="https://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py" target="_blank">ScriptRunConfig class</a></li>


        </ul>
    </div>
</div>
<div id="modal5" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal5">&times;</span>
        <h2>Not using automatic hyperparameter tuning</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Training</p>
        
        <h3>Example:</h3> <p>Developers may not leverage this feature, and they might manually set hyperparameters, 
            leading to a potential suboptimal model performance and increased training time.</p>
        <h3>References:</h3>
        <ul>
            <li><p>Hilde JP Weerts, Andreas C Mueller, and Joaquin Vanschoren. Importance of tuning hyperparameters of machine learning algorithms. arXiv
                preprint arXiv:2007.07588, 2020.
                </p></li>
            <li><p> A Helen Victoria and Ganesh Maragatham. Automatic tuning of hyperparameters using bayesian optimization. Evolving Systems, 12(1):217–
                223, 2021.
                </p></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters?view=azureml-api-2" target="_blank">Hyperparameters tuning</a></li>


        </ul>
    </div>
</div>
<div id="modal6" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal6">&times;</span>
        <h2>Not using training checkpoints</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Training</p>
        
        <h3>Example:</h3> <p> If a model fails and checkpoints have not been saved, the entire
            state is not preserved in memory. Proper use of training checkpoints ensures
            that progress is not lost and allows for more efficient and cost-effective training processes.
</p>

        <h3>References:</h3>
        <ul>
            <li><p>Xiangzhe Xu, Hongyu Liu, Guanhong Tao, Zhou Xuan, and Xiangyu
                Zhang. Checkpointing and deterministic training for deep learning. In
                Proceedings of the 1st International Conference on AI Engineering:
                Software Engineering for AI, pages 65–76, 2022
                </p></li>
            <li><p> Elvis Rojas, Albert Njoroge Kahira, Esteban Meneses,
                Leonardo Bautista Gomez, and Rosa M Badia. A study of
                checkpointing in large scale training of deep neural networks.
                arXiv preprint arXiv:2012.00825, 2020.
                </p></li>
            <li><a href="https://cloud.google.com/architecture/ml-on-gcp-best-practices#use-training-checkpoints-to-save-the-current-state-of-your-experiment" target="_blank">Training checkpoints</a></li>

        </ul>
    </div>
</div>
<div id="modal7" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal7">&times;</span>
        <h2>Bad choice of training compute targets</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Training</p>
        
        <h3>Example:</h3> <p> Developers may use Azure Machine Learning Kubernetes as a
            training compute target only for ML pipelines and Azure ML designer but not
            to train automated ML.
</p>

        <h3>References:</h3>
        <ul>
            <li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target?view=azureml-api-2#training-compute-targets" target="_blank">Training compute targets</a></li>
      
        </ul>
    </div>
</div>
<div id="modal8" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal8">&times;</span>
        <h2>Excluding algorithms in automated ML</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Training</p>
        
        <h3>Example:</h3> <p>The excluded algorithms may provide better accuracy or performance metrics for the developer's 
            specific task/dataset. 
            This probably introduces an unintended bias related to the model selection process.</p>

        <h3>References:</h3>
        <ul>
            <li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml?view=azureml-api-2" target="_blank">Automated machine learning</a></li>

        </ul>
    </div>
</div>
<div id="modal9" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal9">&times;</span>
        <h2>Misinterpreting output</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Testing</p>
        
        <h3>Example:</h3> <p> Developers may misinterpret the score or magnitude as the output of sentiment.
            analysis API. According to Google’s documentation, score or magnitude
            should be used together to judge the sentiment of the input text, which makes it
            prone to human errors.
</p>

        <h3>References:</h3>
        <ul>
            <li><a href="https://cloud.google.com/natural-language/docs/analyzing-sentiment" target="_blank">Cloud Natural Language: Analyzing Sentiment</a></li>
            <li> <p>Wan, C., Liu, S., Hoffmann, H., Maire, M., Lu, S.: Are machine learning cloud apis
                used correctly? In: 2021 IEEE/ACM 43rd International Conference on Software
                Engineering (ICSE). pp. 125–137. IEEE (2021)</p></li>

        </ul>
    </div>
</div>
<div id="modal10" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal10">&times;</span>
        <h2>Ignoring fairness evaluation</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Testing</p>
        
        <h3>Example:</h3> <p>
            Neglecting fairness evaluation can lead to potential biases and unfair predictions about specific
            demographic groups, which may negatively impact the generalizability and
            performance of the model.
</p>

        <h3>References:</h3>
        <ul>
            <li> <p>Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman,
                and Aram Galstyan. A survey on bias and fairness in machine learning.
                ACM computing surveys (CSUR), 54(6):1–35, 2021.</p></li>
                <li> <p>Nuno Antunes, Leandro Balby, Flavio Figueiredo, Nuno Lourenco,
                    Wagner Meira, and Walter Santos. Fairness and transparency of machine
                    learning for trustworthy cloud services. In 2018 48th Annual IEEE/IFIP
                    International Conference on Dependable Systems and Networks Workshops (DSN-W), pages 188–193. IEEE, 2018.</p></li>
            <li><a href="https://docs.aws.amazon.com/pt_br/wellarchitected/latest/machine-learning-lens/mloe-09.html" target="_blank">Review fairness</a></li>
         
        </ul>
    </div>
</div>
<div id="modal11" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal11">&times;</span>
        <h2>Ignoring testing schema mismatch</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Testing</p>
        
        <h3>Example:</h3> <p>
            Amazon ML displays alerts if the schema for the training and evaluation data sources are not consistent. 
            Disabling these alerts can result inin missing discrepancies, such as 
            features present in the training data butabsent in the evaluation data, or 
            detecting unexpected additional features. This oversight can lead to inaccurate model predictions and reduced performance.     
</p>

        <h3>References:</h3>
        <ul>
            <li> <p>Neoklis Polyzotis, Martin Zinkevich, Sudip Roy, Eric Breck, and Steven
                Whang. Data validation for machine learning. Proceedings of machine
                learning and systems, 1:334–347, 2019</p></li>
            <li><a href="https://docs.aws.amazon.com/machine-learning/latest/dg/evaluation-alerts.html" target="_blank">Evaluation Alerts: schema mismatch</a></li>
   
        </ul>
    </div>
</div>
<div id="modal12" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal12">&times;</span>
        <h2>Using suboptimal evaluation metrics</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Testing</p>
        
        <h3>Example:</h3> <p>According
            to the Microsoft ML official documentation in classification tasks, metrics
            such as accuracy, and norm_macro_recall might not perform well on small
            datasets, datasets with significant class imbalance, or when the metric values are
            close to 0.0 or 1.0. In such cases, AUC_weighted could be a better choice.
</p>

        <h3>References:</h3>
        <ul>
            <li> <p>MZ Naser and Amir Alavi. Insights into performance fitness and error
                metrics for machine learning. arXiv preprint arXiv:2006.00887, 2020</p></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train?view=azureml-api-2&tabs=python#primary-metric" target="_blank">Primary metric for evaluation</a></li>
   
        </ul>
    </div>
</div>
<div id="modal13" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal13">&times;</span>
        <h2>Overwriting existing ML APIs without versioning</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Deployment</p>
        
        <h3>Example:</h3><p> 
            When publishing an updated model using Azure ML Studio, if the existing API is overwritten without 
            versioning, and the new model introduces
            unexpected behavior or lower accuracy, it becomes difficult to roll back to the
            previous version, leading to potential disruptions in the production system.
</p>

        <h3>References:</h3>
        <ul>
            <li><a href="https://stackoverflow.com/questions/51940106/what-is-the-best-practice-to-develop-cd-ci-when-you-use-ml-studio-apis" target="_blank">Reference 1</a></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/api-management/api-management-key-concepts" target="_blank">Reference 2</a></li>
            <li><a href="https://docs.aws.amazon.com/comprehend/latest/dg/model-versioning.html" target="_blank">Reference 3</a></li>
     
        </ul>
    </div>
</div>
<div id="modal14" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal14">&times;</span>
        <h2>Choosing the wrong deployment endpoint</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Deployment</p>
        
        <h3>Example:</h3><p> Using a batch endpoint for a real-time task in place of an online endpoint may lead to delayed inferences.        
</p>

        <h3>References:</h3>
        <ul>
            <li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints?view=azureml-api-2" target="_blank">Endpoints for inference in production</a></li>
 
        </ul>
    </div>
</div>
<div id="modal15" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal15">&times;</span>
        <h2>Disabling automatic rollbacks</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Deployment</p>
        
        <h3>Example:</h3> <p>If automatic rollback is disabled, any problem will need to be manually resolved in order to revert 
            to the earlier version of the app following each new deployment with an update. 
            This may result in downtimes because of the time-consuming nature of manual rollback.</p>

        <h3>References:</h3>
        <ul>
            <li><p>Serban, A., Van der Blom, K., Hoos, H., Visser, J.: Adoption and effects of software engineering best practices in machine learning. In: Proceedings of the 14th
                ACM/IEEE International Symposium on Empirical Software Engineering and
                Measurement (ESEM). pp. 1–12 (2020)
                </p></li>
            <li><a href="https://martinfowler.com/articles/cd4ml.html" target="_blank">Continuous Delivery for Machine Learning</a></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/azure-resource-manager/templates/rollback-on-error" target="_blank">Rollback on error to successful deployment</a></li>
            


        </ul>
    </div>
</div>
<div id="modal16" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal16">&times;</span>
        <h2>Disabling automatic scaling for online prediction service</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Deployment</p>
        
        <h3>Example:</h3><p>Developers may turn off automatic scaling when deploying ML models, 
            which can significantly increase inference latency during peak demand for example.</p>

        <h3>References:</h3>
        <ul>
            <li><a href="https://cloud.google.com/blog/products/ai-machine-learning/scaling-machine-learning-predictions?hl=en" target="_blank">How to automatically scale your machine learning predictions</a></li>
            <li><a href="https://cloud.google.com/architecture/ml-on-gcp-best-practices#turn-on-automatic" target="_blank">Best practices for implementing machine learning on Google Cloud </a></li>
            <li><a href="https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html" target="_blank">Application Auto Scaling</a></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-autoscale-endpoints?view=azureml-api-2&tabs=cli" target="_blank">Autoscale online endpoints in Azure Machine Learning</a></li>

    
        </ul>
    </div>
</div>
<div id="modal17" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal17">&times;</span>
        <h2>Improper handling of ML API limits</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Serving</p>
        
        <h3>Example:</h3> <p> 
            Exceeding the maximum
            prompt tokens per request set by the Azure OpenAI service, 
            and not controlling the size of the input prompt may lead to truncating the input to fit with the
            limit, and that leads to information loss.
            
            
</p>

        <h3>References:</h3>
        <ul>
            <li><a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits#quotas-and-limits-reference" target="_blank">Quotas and limits reference</a></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/ai-services/language-service/concepts/data-limits" target="_blank">Service limits for Azure AI Language</a></li>
            <li><a href="https://techcommunity.microsoft.com/t5/fasttrack-for-azure/optimizing-azure-openai-a-guide-to-limits-quotas-and-best/ba-p/4076268" target="_blank">Optimizing Azure OpenAI</a></li>
        </ul>
    </div>
</div>
<div id="modal18" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal18">&times;</span>
        <h2>Misusing Synchronous/Asynchronous APIs with deployment</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Serving</p>
        
        <h3>Example:</h3><p>Developers may ignore choosing the most suitable API request which may increase 
            latency as well as higher memory usage when using asynchronous API with online endpoint for example, 
            because each request may keep certain resources occupied.</p>

        <h3>References:</h3>
        <ul>
            <li><p>Chengcheng Wan, Shicheng Liu, Henry Hoffmann, Michael Maire, and
                Shan Lu. Are machine learning cloud apis used correctly? In 2021
                IEEE/ACM 43rd International Conference on Software Engineering
                (ICSE), pages 125–137. IEEE, 2021
                </p></li>
            <li><a href="https://learn.microsoft.com/en-us/azure/architecture/patterns/async-request-reply" target="_blank">Asynchronous Request-Reply pattern</a></li>
            <li><a href="https://cloud.google.com/vertex-ai/docs/predictions/get-predictions#deploy_a_model_to_an_endpoint" target="_blank">Vertex AI predictions</a></li>

        </ul>
    </div>
</div>

<div id="modal20" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal20">&times;</span>
        <h2>Calling the wrong ML service API</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Serving</p>
        
        <h3>Example:</h3> <p>Image classification and object detection are vision APIs that provide description
            tags for input images. Image classification offers one tag for the entire image,
            while object detection provides a tag for each object. Using image classification
            instead of object detection can cause the software to miss important objects,
            and using object detection instead of image classification can result in incorrect
            image tags.
</p>

        <h3>References:</h3>
        <ul>
            <li><p>Wan, C., Liu, S., Hoffmann, H., Maire, M., Lu, S.: Are machine learning cloud apis
                used correctly? In: 2021 IEEE/ACM 43rd International Conference on Software
                Engineering (ICSE). pp. 125–137. IEEE (2021)</p></li>

        </ul>
    </div>
</div>
<div id="modal21" class="modal">
    <div class="modal-content">
        <span class="close-btn" data-modal="modal21">&times;</span>
        <h2>Ignore monitoring data drift</h2>
        <p><strong>ML Pipeline Development Stage:</strong> Monitoring</p>
        
        <h3>Example:</h3> <p>Developers may not specify a threshold to trigger an alert when
            monitoring data drifts in their features.
</p>

        <h3>References:</h3>
        <ul>
            <li><p>Carol Bova, Carol Jaffarian, Sybil Crawford, Jose Bernardo Quintos,
                Mary Lee, and Susan Sullivan-Bolyai. Intervention fidelity: monitoring
                drift, providing feedback, and assessing the control condition. Nursing
                research, 66(1):54–59, 2017.</p></li>
            <li><p>Ankur Mallick, Kevin Hsieh, Behnaz Arzani, and Gauri Joshi. Matchmaker: Data drift mitigation in machine learning for large-scale systems.
                    Proceedings of Machine Learning and Systems, 4:77–94, 2022.</p></li>
            <li><a href="https://cloud.google.com/architecture/ml-on-gcp-best-practices#fine-tune-alert-thresholds" target="_blank">Google cloud: detect data drift</a></li>

        </ul>
    </div>
</div>




<script>
document.addEventListener('DOMContentLoaded', () => {
    const openButtons = document.querySelectorAll('.open-modal');
    const closeButtons = document.querySelectorAll('.close-btn');
    const modals = document.querySelectorAll('.modal');

    // Open modal
    openButtons.forEach(button => {
        button.addEventListener('click', () => {
            const modalId = button.getAttribute('data-modal');
            document.getElementById(modalId).style.display = 'block';
        });
    });

    // Close modal
    closeButtons.forEach(button => {
        button.addEventListener('click', () => {
            const modalId = button.getAttribute('data-modal');
            document.getElementById(modalId).style.display = 'none';
        });
    });

    // Close modal when clicking outside
    window.addEventListener('click', (event) => {
        if (event.target.classList.contains('modal')) {
            event.target.style.display = 'none';
        }
    });
});

document.addEventListener('DOMContentLoaded', () => {
    const openButtons = document.querySelectorAll('nav ul li a');
    const closeButtons = document.querySelectorAll('.close-btn');
    const modals = document.querySelectorAll('.modal');

    // Open modal
    openButtons.forEach(button => {
        button.addEventListener('click', (event) => {
            event.preventDefault(); // Prevent default link behavior
            const modalId = button.getAttribute('data-modal');
            document.getElementById(modalId).style.display = 'block';
        });
    });

    // Close modal
    closeButtons.forEach(button => {
        button.addEventListener('click', () => {
            const modalId = button.getAttribute('data-modal');
            document.getElementById(modalId).style.display = 'none';
        });
    });

    // Close modal when clicking outside
    window.addEventListener('click', (event) => {
        if (event.target.classList.contains('modal')) {
            event.target.style.display = 'none';
        }
    });
});

</script>

    </main>
    <footer>
        <p>&copy; 2024</p>
    </footer>
</body>
</html>
